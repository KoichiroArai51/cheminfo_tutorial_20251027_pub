{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a10a6683",
   "metadata": {},
   "source": [
    "## This is an example of model training from Jupyter notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330b346c",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "source": [
    "#### import packages and load dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca3b2f1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6d3f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from lightning import pytorch as pl\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "import pandas as pd\n",
    "\n",
    "from chemprop import data, featurizers, models, nn\n",
    "\n",
    "\n",
    "input_path = \"./data.csv\" # path to the input CSV fil\n",
    "num_workers = 0 # number of workers for dataloader. 0 means using main process for data loading\n",
    "smiles_column = 'MOL_smiles' # name of the column containing SMILES strings\n",
    "target_columns = ['LOG_HLM_CLint', \n",
    "                  'LOG_RLM_CLint',\n",
    "                  'LOG_MDR1-MDCK_ER',\n",
    "                  'LOG_HPPB',\n",
    "                  'LOG_RPPB',\n",
    "                   'LOG_SOLUBILITY'] # list of names of the columns containing targets\n",
    "df_input = pd.read_csv(input_path)\n",
    "df_input.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e31c988",
   "metadata": {},
   "source": [
    "#### Data preparation\n",
    "- Get smiles and target data from CSV file\n",
    "- combine structure and target dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7954454",
   "metadata": {},
   "outputs": [],
   "source": [
    "smis = df_input.loc[:, smiles_column].values\n",
    "ys = df_input.loc[:, target_columns].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aea2fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "smis[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b30f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ys[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74a1aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://chemprop.readthedocs.io/en/latest/tutorial/python/data/datapoints.html\n",
    "# Create a list of MoleculeDatapoint objects from SMILES strings and target values\n",
    "all_data = [data.MoleculeDatapoint.from_smi(smi, y) for smi, y in zip(smis, ys)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4ada24",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(data.SplitType.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feebbb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of a random split\n",
    "mols = [d.mol for d in all_data]  # RDkit Mol objects are use for structure based splits\n",
    "train_indices, val_indices, test_indices = data.make_split_indices(mols, \"random\", (0.8, 0.1, 0.1))  # unpack the tuple into three separate lists\n",
    "train_data, val_data, test_data = data.split_data_by_indices(\n",
    "    all_data, train_indices, val_indices, test_indices\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c755303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://chemprop.readthedocs.io/en/latest/autoapi/chemprop/featurizers/index.html#module-chemprop.featurizers\n",
    "featurizer = featurizers.SimpleMoleculeMolGraphFeaturizer()\n",
    "\n",
    "train_dset = data.MoleculeDataset(train_data[0], featurizer)\n",
    "scaler = train_dset.normalize_targets()\n",
    "\n",
    "val_dset = data.MoleculeDataset(val_data[0], featurizer)\n",
    "val_dset.normalize_targets(scaler)\n",
    "\n",
    "test_dset = data.MoleculeDataset(test_data[0], featurizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c061c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = data.build_dataloader(train_dset, num_workers=num_workers)\n",
    "val_loader = data.build_dataloader(val_dset, num_workers=num_workers, shuffle=False)\n",
    "test_loader = data.build_dataloader(test_dset, num_workers=num_workers, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341ae18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp = nn.BondMessagePassing()\n",
    "#agg = nn.MeanAggregation()\n",
    "agg = nn.SumAggregation()\n",
    "output_transform = nn.UnscaleTransform.from_standard_scaler(scaler)\n",
    "ffn = nn.RegressionFFN(n_tasks=len(target_columns), output_transform=output_transform)\n",
    "batch_norm = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdcb9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nn.metrics.MetricRegistry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c30125b",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_list = [nn.metrics.RMSE(), nn.metrics.MAE()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8a08e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpnn = models.MPNN(mp, agg, ffn, batch_norm, metric_list)\n",
    "mpnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d842c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure model checkpointing\n",
    "checkpointing = ModelCheckpoint(\n",
    "    \"note_checkpoints\",  # Directory where model checkpoints will be saved\n",
    "    \"best-{epoch}-{val_loss:.2f}\",  # Filename format for checkpoints, including epoch and validation loss\n",
    "    \"val_loss\",  # Metric used to select the best checkpoint (based on validation loss)\n",
    "    mode=\"min\",  # Save the checkpoint with the lowest validation loss (minimization objective)\n",
    "    save_last=True,  # Always save the most recent checkpoint, even if it's not the best\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343e6bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(\n",
    "    logger=False,\n",
    "    enable_checkpointing=True, # Use `True` if you want to save model checkpoints. The checkpoints will be saved in the `checkpoints` folder.\n",
    "    enable_progress_bar=True,\n",
    "    accelerator=\"auto\",\n",
    "    devices=1,\n",
    "    max_epochs=20, # number of epochs to train for\n",
    "    callbacks=[checkpointing], # Use the configured checkpoint callback\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a88cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(mpnn, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18451bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = trainer.test(dataloaders=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309415a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b922bbe1",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cbi2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
